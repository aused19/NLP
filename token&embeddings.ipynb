{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "89585dc5",
      "metadata": {
        "id": "89585dc5"
      },
      "source": [
        "# Tokens & Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58a0832e",
      "metadata": {
        "id": "58a0832e"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0c1453d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0c1453d8",
        "outputId": "15f42ed4-62c1-46b9-b074-d866e9f1905f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word index ==> {'<OOV>': 1, 'familia': 2, 'la': 3, 'es': 4, 'visitar': 5, 'sagrada': 6, 'a': 7, 'estupenda': 8, 'quiero': 9, 'voy': 10, 'mi': 11, 'odio': 12, 'barcelona': 13, 'fea': 14, 'no': 15, 'me': 16, 'gustan': 17, 'las': 18, 'visitas': 19}\n",
            "sequences ==> [[3, 2, 4, 8], [9, 5, 3, 6, 2], [10, 7, 5, 7, 11, 2], [12, 13], [3, 6, 2, 4, 14], [15, 16, 17, 18, 19]]\n"
          ]
        }
      ],
      "source": [
        "sentences = [\n",
        "    'la familia es estupenda',\n",
        "    'Quiero visitar la Sagrada familia',\n",
        "    'voy a visitar a mi familia',\n",
        "    'odio Barcelona',\n",
        "    'La sagrada familia es fea',\n",
        "    'no me gustan las visitas'\n",
        "]\n",
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\") #Crear tokenizador\n",
        "#Cuando no existe una palabra en el vocabulario ponemos oov_token=\"\"\n",
        "tokenizer.fit_on_texts(sentences)#Entrenar tokenizador\n",
        "word_index = tokenizer.word_index\n",
        "print('word index ==>', word_index)#Observamos los vectores asociados a las palabras\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "print('sequences ==>', sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57c68562",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57c68562",
        "outputId": "8474769b-be2f-45b3-b436-41313bbc87c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padded Sequences:\n",
            "[[ 0  0  0  3  2  4  8]\n",
            " [ 0  0  9  5  3  6  2]\n",
            " [ 0 10  7  5  7 11  2]\n",
            " [ 0  0  0  0  0 12 13]\n",
            " [ 0  0  3  6  2  4 14]\n",
            " [ 0  0 15 16 17 18 19]]\n"
          ]
        }
      ],
      "source": [
        "#Padding= Añadir ceros\n",
        "padded = pad_sequences(sequences, maxlen=7)#Longitud de 7\n",
        "print(\"\\nPadded Sequences:\")\n",
        "print(padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87815e8f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87815e8f",
        "outputId": "985fc3e4-67f9-4191-8802-a285f6bb8c7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word index ==> {'<OOV>': 1, 'visitar': 2, 'familia': 3, 'a': 4, 'es': 5, 'adoro': 6, 'horrible': 7, 'la': 8, 'mi': 9, 'sagrada': 10, 'madrid': 11, 'para': 12, 'voy': 13, 'barcelona': 14, 'las': 15, 'visitas': 16, 'mis': 17, 'primos': 18, 'esta': 19, 'en': 20, 'el': 21, 'turismo': 22, 'masivo': 23, 'estupenda': 24, 'quiero': 25, 'odio': 26, 'fea': 27, 'no': 28, 'me': 29, 'gustan': 30}\n",
            "\n",
            "Test Sequence =  [[13, 4, 2, 4, 17, 18], [8, 10, 3, 19, 20, 14], [6, 15, 16], [5, 7, 21, 22, 23]]\n",
            "\n",
            "Padded Test Sequence: \n",
            "[[ 0 13  4  2  4 17 18]\n",
            " [ 0  8 10  3 19 20 14]\n",
            " [ 0  0  0  0  6 15 16]\n",
            " [ 0  0  5  7 21 22 23]]\n"
          ]
        }
      ],
      "source": [
        "test_data = [\n",
        "    'voy a visitar a mis primos',\n",
        "    'La sagrada familia esta en Barcelona',\n",
        "    'adoro las visitas',\n",
        "    'es horrible el turismo masivo'\n",
        "]\n",
        "tokenizer.fit_on_texts(test_data)#Entrenar tokenizador\n",
        "word_index = tokenizer.word_index\n",
        "print('word index ==>', word_index)\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "print(\"\\nTest Sequence = \", test_seq)\n",
        "\n",
        "test_padded = pad_sequences(test_seq, maxlen=7)\n",
        "print(\"\\nPadded Test Sequence: \")\n",
        "print(test_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e29a44c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e29a44c",
        "outputId": "65cb4d4d-4c09-47c2-f731-6faca7535bc4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1 1 1 0 0 0]\n",
            "[[ 0  0  7  2  4  6  3]\n",
            " [ 0  0 10  5  8 11  2]]\n"
          ]
        }
      ],
      "source": [
        "sentiments = np.array([1,1,1,0,0,0])#Son como las etiquetas, en entrenamiento tenemos las tres primeras reseñas positivas (=1) y las tres últimas negativas (=0)\n",
        "training_padded = np.array(padded)\n",
        "print(sentiments)\n",
        "print(training_padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "520542cd",
      "metadata": {
        "id": "520542cd"
      },
      "outputs": [],
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 20 #Tamaño del vector del embedding\n",
        "max_length = 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8990a87c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8990a87c",
        "outputId": "0f2d87da-a307-4e48-d339-39d675565af6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(vocab_size, embedding_dim, input_length=max_length))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3ad2b340",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 242
        },
        "id": "3ad2b340",
        "outputId": "9c813ad7-f988-4c36-acbf-6123d89779c8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (\u001b[38;5;33mEmbedding\u001b[0m)              │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ embedding_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)              │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecd94cd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "collapsed": true,
        "id": "ecd94cd0",
        "outputId": "87d67d7a-9f6c-43d9-ea9e-eae3154ce843"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 2\n'y' sizes: 6\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-6323b76bac7b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_padded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentiments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/data_adapter_utils.py\u001b[0m in \u001b[0;36mcheck_data_cardinality\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    112\u001b[0m             )\n\u001b[1;32m    113\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34mf\"'{label}' sizes: {sizes}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Data cardinality is ambiguous. Make sure all arrays contain the same number of samples.'x' sizes: 2\n'y' sizes: 6\n"
          ]
        }
      ],
      "source": [
        "model.fit(training_padded, sentiments, epochs=200, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8281eb8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8281eb8b",
        "outputId": "f96d2fd2-9c5e-471c-933e-3a0b2d5399cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 0 13  4  2  4 17 18]\n",
            " [ 0  8 10  3 19 20 14]\n",
            " [ 0  0  0  0  6 15 16]\n",
            " [ 0  0  5  7 21 22 23]]\n",
            "[1 1 1 0]\n"
          ]
        }
      ],
      "source": [
        "test_padded = np.array(test_padded)\n",
        "test_sentiments = np.array([1,1,1,0])\n",
        "print(test_padded)\n",
        "print(test_sentiments)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c683bbc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c683bbc",
        "outputId": "04709e80-70fa-4f99-ecf1-dd29bc8b41af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 100.000000\n"
          ]
        }
      ],
      "source": [
        "loss, accuracy = model.evaluate(test_padded, test_sentiments, verbose=0)\n",
        "print('Accuracy: %f' % (accuracy*100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "830d47d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "830d47d9",
        "outputId": "60a1d938-b77f-4cfe-8144-c14adfce704a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'<OOV>': 1, 'visitar': 2, 'familia': 3, 'a': 4, 'es': 5, 'mi': 6, 'adoro': 7, 'horrible': 8, 'la': 9, 'madrid': 10, 'para': 11, 'sagrada': 12, 'voy': 13, 'barcelona': 14, 'las': 15, 'visitas': 16, 'estupenda': 17, 'quiero': 18, 'odio': 19, 'fea': 20, 'no': 21, 'me': 22, 'gustan': 23, 'mis': 24, 'primos': 25, 'esta': 26, 'en': 27, 'el': 28, 'turismo': 29, 'masivo': 30}\n",
            "[[7, 2, 4, 6, 3], [10, 5, 8, 11, 2]]\n",
            "[[ 0  0  7  2  4  6  3]\n",
            " [ 0  0 10  5  8 11  2]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "[[0.6140113 ]\n",
            " [0.89589375]]\n"
          ]
        }
      ],
      "source": [
        "sentence = [\"adoro visitar a mi familia\", 'Madrid es horrible para visitar']\n",
        "tokenizer.fit_on_texts(sentence)\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)\n",
        "sequences = tokenizer.texts_to_sequences(sentence)\n",
        "print(sequences)\n",
        "padded = pad_sequences(sequences, maxlen=max_length)\n",
        "print(padded)\n",
        "print(model.predict(padded))"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.7"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}